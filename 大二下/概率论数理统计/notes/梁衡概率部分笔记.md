# readme

- 梁衡老师的概统讲的很好，~~少数我想线下听的课~~，可惜也没好好听
- 听人说，梁衡老师的考试很能区分你听没听课，下没下功夫，反正没见人 rush 成功的
- 把时间用在小测和习题课上可比卷美赛国赛好多了
- 概统对机器学习意义大多了
- 我总结下每一章比较有意思的地方，这一部分是概率部分，统计部分见其他篇章
- 在写这篇博客的时候，我的图床挂了一次，吓得我赶快换了个图床，瞎折腾了很久，学会了博客内镶图床

<img src="https://zhaochenyang20.github.io/pic/embed/spring4.jpg" style="zoom:33%;" />

- 这张照片是我的好朋友一多在伦敦拍的，祝他春假快乐

#  课程学习的观念

- 数学成熟的提升：

  > 用到数学的时候我不会害怕，真的知道它，它是你的工具，你能够驾驭

- 什么是微积分：

	>微积分（Calculus），数学概念，是高等数学中研究函数的微分(Differentiation)、积分(Integration)以及有关概念和应用的数学分支。 它是数学的一个基础学科，内容主要包括极限、微分学、积分学及其应用。 微分学包括求导数的运算，是一套关于变化率的理论。

- 课堂笑话：

	> 你是个程序员，说出来就放你走，说不出来就枪毙你！
	>
	> js 里 9+“1” 等于多少？

# Lecture 1 引言

$$
\sum_{k=1}^{n}k\times C^k_n=n\times 2^{n-1}\\
对(x+1)^n = \sum^n_{k=0}C^L_N\times x^k求导
$$

可以参考[这个](https://www.youtube.com/watch?v=wkFm2K8mvmg)。

- [示性函数](https://zh.wikipedia.org/wiki/%E7%A4%BA%E6%80%A7%E5%87%BD%E6%95%B0)，P21
- P26 页例子，经典的利用不大于作差得到恰好关系的例子
- P27 页，整道题都值得打磨

> 1. 事件的表示
> 2. 超集大小的算法
> 3. $P(A_{i_1}\dots A_{i_k})$ 的算法与独立性
> 4. $\sum^{n}_{1}P(A_i)=1$
> 5. $e^x$ 的展开

# Lecture 2 条件概率

- P4，经典问题，参考阶段自测
- P8，严谨的概率语言——三次都是白色的概率必然建立在之前抽到的每一次都是白色，所以是条件概率
- P10，全概率公式的定义
- P15，贝叶斯公式直观理解
- P17，经典问题，虚惊一场的概率高到 70%
- P18，转换为独立无穷概率求和
- P22，类比多元统计的相互独立性，第 6 章 P
- P23，相关系数
- [事件的相关系数](https://zhuanlan.zhihu.com/p/70154991)

> 对于任意事件 $A$, 可以定义一个与之相关的随机变量 $X_{A}$ : 当事件 $A$ 发生时, $X_{A}$ 取1, 否则取 0。于是数学期望 $\mathbb{E} X_{A}=P(A)$, 方差 $\operatorname{var}\left[X_{A}\right]=P(A) P(\bar{A})$ 。
> 对于两个事件 $A, B$, 可以考察相应随机变量的协方差与相关系数
> $$
> \begin{array}{l}
> \operatorname{cov}\left(X_{A}, X_{B}\right)=P(A B)-P(A) P(B) \\
> \operatorname{corr}\left(X_{A}, X_{B}\right)=\frac{P(A B)-P(A) P(B)}{\sqrt{P(A) P(\bar{A}) P(B) P(\bar{B})}}
> \end{array}
> $$
> 定义两个事件的相关系数 $\chi(A, B)=\operatorname{corr}\left(X_{A}, X_{B}\right)$ 。
>
> 经过一些数学整理可得
> $$
> P(A B) P(\bar{A} \bar{B})-P(\bar{A} B) P(A \bar{B})=P(A B)-P(A) P(B)
> $$
> 于是可以得到相关系数的一个等价表示
> $$
> \chi(A, B)=\frac{P(A B) P(\bar{A} \bar{B})-P(\bar{A} B) P(A \bar{B})}{\sqrt{P(A) P(\bar{A}) P(B) P(\bar{B})}}
> $$

# Lec 3 离散型随机变量

- P4，随机变量：定义在样本空间上的函数，随机变量是函数——样本的定量表达
- P6，示性函数
- P8，分布函数的定义，边界情况，区分 $F$ 与 $P$

$$
\forall x,F(x)=P(X\le x)
$$

- P10，分布列，可列分布
- P12，伯努利分布
- P14，二项分布——分布列类似钟形，分布函数类似高中生物的 [S 形曲线](https://baike.baidu.com/item/S%E5%9E%8B%E5%A2%9E%E9%95%BF%E6%9B%B2%E7%BA%BF/12979174)

> $$
> f(k, n, p)=\operatorname{Pr}(X=k)=\left(\begin{array}{l}
> n \\
> k
> \end{array}\right) p^{k}(1-p)^{n-k}
> $$
> 对于 $k=0,1,2, \ldots, n$, 其中 $\left(\begin{array}{l}n \\ k\end{array}\right)=\frac{n !}{k !(n-k) !}$
>
> 累积分布函数可以表示为:
> $$
> F(x ; n, p)=\operatorname{Pr}(X \leq x)=\sum_{i=0}^{\lfloor x\rfloor}\left(\begin{array}{c}
> n \\
> i
> \end{array}\right) p^{i}(1-p)^{n-i}
> $$
> 其中 $\lfloor x\rfloor$ 是小于或等于 $x$ 的最大整数。
>
> 如果 $X \sim B(n, p)$ (也就是说, $X$ 是服从二项分布的随机变量）, 那么X的期望值为  $\mathrm{E}[X]=n p$。方差为 $\operatorname{Var}[X]=n p(1-p)$。

- P17，Poisson Distribution，泊松分布——**小概率事件被大量重复时的近似**
- 先有泊松定理（P20），也即泊松近似，之后整理为泊松分布

$$
近似若  X \sim B(n, p), Y \sim P(n p) , 则  P(X=k) \approx P(Y=k),
 \hat{\nabla} \lambda=\mathrm{np} ,\\ 则  \frac{B_{k}(n, p)}{B_{k-1}(n, p)}=\frac{\lambda-(k-1) p}{k(1-p)} \approx \frac{\lambda}{k} 
\\同时 B_{0}(n, p)=(1-p)^{n}=\left(1-\frac{\lambda}{n}\right)^{n}=\left(1+\left(-\frac{\lambda}{n}\right)\right)^{\left(-\frac{n}{\lambda}\right)(-\lambda)} \approx e^{-\lambda} \\
 B_{1}(n, p) \approx \lambda B_{0}(n, p) \approx \lambda e^{-\lambda}, B_{2}(n, p) \approx \frac{\lambda}{2} B_{1}(n, p) \approx \frac{\lambda^{2}}{2} e^{-\lambda}, \cdots, \\B_{k}(n, p) \approx \frac{\lambda^{k}}{k !} e^{-\lambda}
$$

> 其实这个形式还蛮好记的，毕竟 $\frac{\lambda^k}{k!}$ 是 $e^{\lambda}$ 的泰勒展开。

- P27，[几何分布](https://zh.wikipedia.org/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88)

$$
p_{X}(k)=(1-p)^{k-1} p, \quad k=1,2, \cdots
$$

- P28，几何分布的无记忆性，无记忆性则符合几何分布

> 如果随机变量X ~ Ge(p)，则对于任意非负整数s, t，有：
> $$
> P(X>s+t|X>s)=P(X>t)
> $$

- P30，[负二项分布](https://zh.wikipedia.org/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83)——关于组合数的扩展定义

> 负二项分布（Negative binomial distribution）是[统计学](https://zh.wikipedia.org/wiki/統計學)上一种描述在一系列独立同分布的伯努利试验中，**成功次数到达指定次数（记为 r ）时总共实验(失败)次数的[离散概率分布](https://zh.wikipedia.org/wiki/离散概率分布)**。比如，如果我们定义掷骰子随机变量 x 值为 x=1 时为成功，所有 x≠1 为失败，这时我们反复掷骰子直到 1 出现 3 次（成功次数 r = 3 ），此时非 1 数字出现次数的概率分布即为负二项分布。

例一、假设随机变量 $X \sim N b(6,0.05)$, 则 $E(X)=(\quad)\quad Var(X)=(\quad)$
$$
X_{1}, \cdots, X_{6} \sim G e(0.05), \quad E(X)=E\left(X_{1}+\cdots+X_{6}\right)=6 \cdot \frac{1}{0.05}=120\\
Var(X)=Var(X_{1}+\cdots+X_{6})=6\cdot \frac{1-p}{p^2}=2280
$$

例二、$X_{1}+X_{2}+\cdots+X_{n} \sim N b(n, p)$
$$
P\left(X_{1}+X_{2}+\cdots+X_{n}=k\right)=\left(\begin{array}{c}
k-1 \\
n-1
\end{array}\right) p^{n}(1-p)^{k-n}, \quad k \geq n
$$
> 一共要成功 n 次，每次实验成功的概率为 p，统共实验 k 次的概率，也即前 k - 1 次需要成功 n - 1 次，一共成功 n 次，但是最后一次必然成功。
>
>  形式上和二项分布相似，概率意义上与几何分布更密切。首先注意概率意义，其次是数学形式:smile:

# Lecture 4 连续性离散变量

- P4，分布函数的基本性质——单调有界，右连续
- - 任意分布函数都是**右**连续的

> $P(X=a)=F(a)-F(a-0)$

- P6，连续型随机变量的定义，概率密度函数的定义，probability density function
- 连续型随机变量某点的取值不等于概率，某段积分值才等于概率
- P8，柯西分布，没有期望，没有平均值，$F(x)=\frac{arctan(x)+\frac{\pi}{2}}{\pi}$

$$
p(x)=\frac{1}{\pi}\times \frac{1}{1+x^2}
$$

- P9 与 P10，P 9 是有记忆性的，P 10 是无记忆性—— P9 不是指数分布
- P10，指数分布与几何分布具有无记忆性

$$
PDF:f_{X}(x)=\left\{\begin{array}{ll}
\lambda \mathrm{e}^{-\lambda x}, & \text { 若 } x \geqslant 0 \\
0, & \text { 其他 }
\end{array}\right.\\CDF:F(x)=1-e^{-\lambda x}\\P(x\ge t)=e^{-\lambda t}
$$

> 感谢华子大学给我打下的优秀数理基础，我现在一点积分都不会做了，给几个积分，直接背下来，遇到不会就换元
> $$
> \int_{0}^{+\infty} x \cdot e^{-x} d x=\int_{0}^{+\infty} e^{-x} d x=1
> \\\int_{0}^{+\infty} x^2\cdot e^{-x} d x=2\\\int_{0}^{+\infty} x^n \cdot e^{-x} d x=n!
> $$
>

- P13，证明指数分布与几何分布的联系，服从参数为 $1-e^{-\lambda}$ 的几何分布
- 大量的独立同分布的随机变量(不必须为正态)的和的分布近似地服从正态分布，而这个事实与各个和项的具体分布无关，此即[中心极限定理，CLT 定理](https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86)

> 设 $X_{1}, X_{2} \cdots$ 是独立同分布的随机变量序列, 序列的每一项的均值为 $\mu$, 方 差为 $\sigma^{2}$. 记
> $$
> Z_{n}=\frac{X_{1}+\cdots+X_{n}-n \mu}{\sqrt{n} \sigma} .
> $$
> 则 $Z_{n}$ 的分布函数的极限分布为标准正态分布函数
> $$
> \Phi(x)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} \mathrm{e}^{-z^{2} / 2} \mathrm{~d} z,
> $$
> 即 $\lim _{n \rightarrow \infty} \mathrm{P}\left(Z_{n} \leqslant x\right)=\Phi(x)$ 对任意的 $x$ 成立.
>
> 很好理解，因为期望是直接相加的，而独立的变量间方差也是直接相加，但是正态分布还要除以标准差，所以要开根号。
>
> 比如扔骰子，每个面出现的概率不是正态分布，但是扔 100000 次的和符合正态分布。一般的，$B(n,p)$ 近似于 $N(np,np(1-p))$

- P17，正态分布的定义，经验法则：68%，95%,99.7%…

- P23，随机变量函数的分布

> 计算连续随机变量 $X$ 的函数 $Y=g(X)$ 的概率密度函数 (PDF)
>
> 使用如下公式计算 $Y$ 的概率函数 (CDF) $F_{Y}$:
>
> $$
> Y=g(X)\Rightarrow F_Y(y)=P(g(X)\le y)=\int_{\{x \mid g(x) \leqslant y\}} f_{X}(x) \mathrm{d} x .
> $$
> 对 $F_{Y}$ 求导, 得到 $Y$ 的 $\mathrm{PDF}$ :
> $$
> f_{Y}(y)=\frac{\mathrm{d} F_{Y}}{\mathrm{~d} y}(y) .
> $$
>
> 
>
> 同样，对于多元变量的函数也如此。设随机变量 $X, Y$ 独立且均在 $(0,6)$ 上服从均匀分布, 则 $\operatorname{Var}(\min (X, Y))=(\quad)$
>
> 由题设可知, $F_{X}(x)=\left\{\begin{array}{cc}0, & x \leq 0 . \\ \frac{x}{\theta}, & 0<x<\theta . \\ 1, & x \geq \theta .\end{array}\right.$
> $$
> \text { 且 } F_{Z}(z)=P(\min (X, Y)<z)=1-\left(1-F_{X}(z)\right)^{2}\\=\left\{\begin{array}{cc}
> 0, & z \leq 0 . \\
> \frac{2 z}{\theta}-\frac{z^{2}}{\theta^{2}}, & 0<z<\theta . \\
> 1, & z \geq \theta .
> \end{array}\right.
> $$
> 于是 $Z$ 的密度函数为 $p(z)=F_{Z}^{\prime}(z)=\left\{\begin{array}{cc}\frac{2}{\theta}-\frac{2 z}{\theta^{2}}, & 0<z<\theta, \\ 0, & \text { 其他. }\end{array}\right.$
> $$
> \operatorname{Var}[\min (X, Y)]=E\left(Z^{2}\right)-(E(Z))^{2}=\\\int_{0}^{\theta} z^{2}\left(\frac{2}{\theta}-\frac{2 z}{\theta^{2}}\right) \mathbf{d} z-\left(\int_{0}^{\theta} z\left(\frac{2}{\theta}-\frac{2 z}{\theta^{2}}\right) \mathbf{d} z\right)^{2}\\=\frac{2 \theta^{2}}{3}-\frac{\theta^{2}}{2}-\left(\theta-\frac{2 \theta}{3}\right)^{2}=\frac{\theta^{2}}{18}
> $$
>

- P25，据 y 和 g(X) 性质，反解出 X 的取值范围，然后做不定积分等等求出这个范围内的 P(X)
- P27，感觉这一块梁老师的课件讲的不太清楚，我之后会给他说一声
- 这一块大概的讨论的是逆变换采样的问题，实际上这点非常有意思，他有着强烈的计算机背景

> 假定计算机可以模拟 $[0, 1]$上均匀分布的随机变量 U，U 称为伪随机数。基于此模拟任意的分布——也即[逆变换采样](https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7)

- 结合梁老师的课件和 wiki：

$$
\text{For any function F which follows:}
\\ F(-\infty)=0\le F(X)\le F(+\infty)\\
\text{The distribution function for }y=F^{-1}{(x)}\text{ is }F(y)\\
\text{ where x follows uniformity distribution in } [0,1]
$$

- 说人话就是，我先给定一个函数 F(X)，希望能够模拟符合 F(X) 分布的随机样本。首先验证 F(X) 是否符合极限条件，然后反解方程 $F(F^{-1}(x))=x$，得到的 $y = F^{-1}(X)$ 即为符合 $F(y) $ 分布的随机变量。
- P28，如下的例子，给出两个答案都是对的，这是因为：

> 对于均匀分布 X 和 1-X 同分布

$$
F(x)=1-e^{-\lambda x}\\
F^{-1}(x)=\frac{ln^{(1-x)}}{-\lambda}\\
不过，老师给出的是 F(x)=\frac{ln^{(x)}}{-\lambda}
$$

> 如果随机变量 $X \sim U(0,1)$, 则 $Y=\frac{-\ln X}{\lambda}$ 服从参数为 $\lambda$ 的指数分布。 当 $x \in(0,1)$ 时, $\frac{-\ln x}{\lambda}>0$。所以, 当 $y \leq 0$ 时, $F_{Y}(y)=P(Y \leq y)=0$，当 $y\ge 0 $ 时，$\begin{aligned}
> F_{Y}(y) &=P(Y \leq y)=P\left(\frac{-\ln X}{\lambda} \leq y\right)=P(\ln X \geq-\lambda y)=P\left(X \geq e^{-\lambda y}\right)=1-e^{-\lambda y}
> \end{aligned}$所以 $Y \sim \operatorname{Exp}(\lambda)$ 。

- 变量 X 符合某个分布 F(x)：$P(X\le y)=F(y)$，变量 X 小于某个特定的值 y 的概率为 F(y)
- P29，存在既非连续也非离散的随机变量

# Lecture 5 随机变量的数字特征：期望与方差

- P3，期望的定义与存在条件——某种意义上的绝对收敛…

$$
\int\limits_{-\infty}^{+\infty}p(x)|x|dx<\infty
$$

- P9，方差的定义

$$
Var(X)=E(X^2)-E(x)^2
$$

- P11，二项分布的期望与方差，$np,np(1-p)$
- P13，伯努利分布( 两点分布 )的期望与方差，$p,p(1-p)$
- P14，泊松分布的期望与方差，基于二项分布的极限是泊松分布来理解，$np=\lambda,np(1-p)=\lambda$
- P14，几何分布的期望与方差，基于物理意义的理解，第一次出现成功实验的次数大概等于 $\frac{1}{p}，Var(X)=\frac{1-p}{p^2}$
- P15，均匀分布，$\frac{a+b}{2},\frac{(a-b)^2}{12}$，均匀分布的期望明显与分布的区间位置以及区间的长度有关
- P15，指数分布，$\frac{1}{\lambda},\frac{1}{\lambda^2}$
- P16，基于指数分布的期望计算积分
- P17，正态分布的期望与方差，$\mu,\sigma^2$，$\varphi (x)=\frac{1}{\sqrt[]{2\pi} }e^{-\frac{x^2}{2}}$

> $$
> f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-(x-\mu)^{2} /\left(2 \sigma^{2}\right)}
> $$
>

- P18，基于正态分布的期望计算积分

- P19，存在期望与方差均不存在的随机变量——柯西分布

- [几何分布](https://zh.wikipedia.org/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88)：

  > 在[概率论](https://zh.wikipedia.org/wiki/概率论)和[统计学](https://zh.wikipedia.org/wiki/统计学)中，**几何分布**（英语：Geometric distribution）指的是以下两种离散型[概率分布](https://zh.wikipedia.org/wiki/機率分佈)中的一种：
  >
  >- 在[伯努利试验](https://zh.wikipedia.org/wiki/伯努利試驗)中，得到一次成功所需要的试验次数*X*。*X*的值域是{ 1, 2, 3, ... }
  >
  >- 在得到第一次成功之前所经历的失败次数*Y* = *X* − 1。*Y*的值域是{ 0, 1, 2, 3, ... }
  >
  >实际使用中指的是哪一个取决于惯例和使用方便。

- P21，切比雪夫不等式：与平均相差 $k$ 个标准差以上的值，数目不多于 $\Large{\frac{1}{k^2}}$

$$
P(|X-E(X)| \geq b) \leq \frac{\operatorname{Var}(X)}{b^{2}}
$$

- P23，原点矩与中心矩的概念，期望是一阶原点矩，方差是二阶中心矩

- 期望的最小二乘性质：

> $$
> \min E\left((X-c)^{2}\right)=\operatorname{Var}(X), \text { where } c=E(x)
> $$

# Lecture 6 多维随机变量

- P2，随机向量和联合分布函数
- P5，多维联合分布函数的性质：单调有界，右连续，非负
- P6，二维非负性：主对角线之和减去次对角线之和非负
- P9，边缘分布列
- P12，连续型随机变量和联合密度函数，边际密度函数，编辑分布函数（联系 P9 边缘分布列）
- P16，随机变量的独立性
- P18，概率推断
- P19，即便 $p(x,y)=f(x)\times g(y)$，也不能断言 X, Y 独立分布
- P21，独立同分布

> 在[概率论](https://zh.wikipedia.org/wiki/概率论)与[统计学](https://zh.wikipedia.org/wiki/统计学)中，**独立同分布**（英语：**Independent and identically distributed**，或称独立同分配，缩写为iid、 i.i.d.、IID）是指一组[随机变量](https://zh.wikipedia.org/wiki/随机变量)中每个变量的[概率分布](https://zh.wikipedia.org/wiki/概率分布)都相同，且这些随机变量互相[独立](https://zh.wikipedia.org/wiki/独立_(概率论))

- P23，X + Y 的分布
- P24，独立随机变量的期望与方差

$$
E(XY) = Cov(X,Y)+E(X)E(Y)=E(X)E(Y)
$$

$$
Var(X+Y)=Var(X)+Var(Y)+2\cdot Cov(X,Y)\\=Var(X)+Var(Y)+2\cdot Corr(X,Y)\cdot \sigma(X_1)\cdot \sigma(X_2)\\=Var(X)+Var(Y)
$$

- 这样岂不是能得出 $E(X^2)=E(X)^2$ ，当然不是，因为随机变量两个都是 X 的话，二者当然是不独立的…
- P26，多项分布
- P27，三项分布的边际分布为二项分布
- P28，n 维均匀分布
- P29，二维正态分布
- P31，二维正态分布的对称性，二维正态分布的边际密度即为一维正态分布——背住
- P33，二维正态分布的向量表示
- P34，多元正态分布

# Lecture 7 协方差、相关系数与条件分布

- P1，协方差(Covariance)定义——从直观上来理解，协方差反应的是数据的相关程度，X 大于 E(X) 时，如果 Y 同时大于 E(Y)，X 小于 E(X) 时，如果 Y 同时小于 E(Y) ，则是正相关。如果变量之间不相关，那么协方差为 0；也可以理解为两个数据一同波动的程度。

$$
Cov(X,Y)=E((X-E(X))(Y-E(Y))=E(XY)-E(X)E(Y)
$$

> 反之，$E(XY) = Cov(X,Y)+E(X)E(Y)$

- P2，协方差是内积运算
- P2 + P3，协方差的性质——内积性

> $[\operatorname{Cov}(X, Y)]^{2} \leq \operatorname{Var}(X) \cdot \operatorname{Var}(Y)=\sigma_{X}{ }^{2} \cdot \sigma_{Y}^{2}$

- P6，相关系数：相关系数是将随机变量做方差为 1 的标准化后的协方差

$$
Corr(X,Y)=Cov(\frac{X}{\sigma(X)},\frac{Y}{\sigma(Y)})=\frac{Cov(X,Y)}{\sigma(X)\cdot \sigma(Y)}——内积的性质
$$

- 可以证明 $\rho=1(\rho=-1)$ 当且仅当存在一个正的 (负的) 常数 $c$， 使得

$$
Y-\mathrm{E}[Y]=c(X-\mathrm{E}[X])
$$

- P7，[Cauchy-Schwarz 不等式](https://baike.baidu.com/item/%E6%9F%AF%E8%A5%BF%E2%80%94%E6%96%BD%E7%93%A6%E8%8C%A8%E4%B8%8D%E7%AD%89%E5%BC%8F/4699871)——完全不能理解讲义的意思（梁老师貌似写错了…）
  $$
  对于内积运算：(x,y)^2\le (x,x)\cdot (y,y)\\\text{协方差是一种内积运算}：Cov(X,X)=Var(X)
  $$

- P8，协方差的性质应用如果变量之间不相关，那么协方差为 0，此处是独立同分布，独立是比不相关更强的条件

- P9，线性相关系数：相关系数反应的是随机变量之间在线性关系意义下的相关程度，所以也称为（线性）相关系数

- P9，所谓的不相关是指不存在（线性）相关的关系，相关系数并不能充分表达非线性的相关关系

- P14，二元正态分布的边缘分布为一元正态分布（反之不然），且对于二元正态分布而言，独立等价于不相关

> $$
> f(x, y)=\left(2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}\right)^{-1} \exp \left[-\frac{1}{2\left(1-\rho^{2}\right)}\left(\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}-\frac{2 \rho\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}}\right)\right]
> $$
> 其中 $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$ 都是常数, 我们称 $\left(X_{1}, X_{2}\right)$ 服从参数为 $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$ 的二维正态分布, 常把这个分布记作 $N\left(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho\right)$ ) 。 $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$ 的范围分别为 $-\infty<\mu_{1}<+\infty ;-\infty<\mu_{2}<+\infty ;-1<\rho<1$ $\sigma_{1}>0 ; \sigma_{2}>0$ 。这个函数在三维空间中的图像是一个椭圆切面的钟倒扣在 $O x_{1} x_{2}$ 平面上，其中心在 $\left(\mu_{1}, \mu_{2}\right)$ 点。
>
> 二维随机变量 $(X, Y)$ 的联合密度函数为
> $$
> p(x, y)=\frac{1}{6 \sqrt{3} \pi} \exp \left\{\frac{-2}{3}\left[\frac{x^{2}}{9}+\frac{x y-x}{6}+\frac{(y-1)^{2}}{4}\right]\right\} \text {, }
> $$
> 令 $U=3 X+1, V=5-2 Y$, 则 $\operatorname{Corr}(U, V)=()$
> 这个题最麻烦的地方在于，需要看出： $(X, Y) \sim N\left(0,1,3^{2}, 2^{2},-0.5\right)$

- P15，随机变量和的期望

$$
Var(X+Y)=Var(X)+Var(Y)+2\cdot Cov(X,Y)=Var(X)+Var(Y)+2\cdot Corr(X,Y)\cdot \sigma(X_1)\cdot \sigma(X_2)
$$

>  考虑到 cov 是内积运算，其实这个公式就是平方和公式
>
> 更近一步，考虑下式：
> $$
> X_1,X_2 \quad i.i.d.\\\text{Hence } Var(X_1+X_2)=Var(X_1)+Var(X_2)\\Var(2X_1)=Var(X_1)+Var(X_1)+2\cdot 1\cdot Var(X_1)=4\cdot Var(X_1)
> $$

- P16，随机变量函数的期望
- P19，条件分布，类似于边缘分布
- P20，例子——离散分布的条件分布，结合 P21 页泊松分布的可加性理解

> **可加性**
>
> 1. 二项分布
>
>    $X \sim B(m, p),Y \sim B(n, p), X, Y$ 相互独立, 则 $X+Y \sim B(m+n, p)$
>
> 2. 泊松分布
>
>    $X$ 服从参数为 $\lambda_{1}$ 的泊松分布, $Y$ 服从参数为 $\lambda_{2}$ 的泊松分布, $X$ 与 $Y$ 相互独立, $Z=X+Y$, 则 $Z$ 服从参数为 $\lambda_{1}+\lambda_{2}$ 的泊松分布
>
> 3. 正态分布
>
>    如果 $X \sim N\left(\mu, \sigma^{2}\right)$ 且a与b是实数, 那么 $a X+b \sim N\left(a \mu+b,(a \sigma)^{2}\right)$ 
>
>    如果 $X \sim N\left(\mu_{X}, \sigma_{X}^{2}\right)$ 与 $Y \sim N\left(\mu_{Y}, \sigma_{Y}^{2}\right)$ 是统计独立的正态随机变量, 那么:
>
>    它们的和也满足正态分布 $U=X+Y \sim N\left(\mu_{X}+\mu_{Y}, \sigma_{X}^{2}+\sigma_{Y}^{2}\right)$
>
>    它们的差也满足正态分布 $V=X-Y \sim N\left(\mu_{X}-\mu_{Y}, \sigma_{X}^{2}+\sigma_{Y}^{2}\right)$.
>
>    $X$ 与 $Y$ 方差相等时， $U$ 与 $V$ 二者独立。
>
>    实际上如果方差不相等，也能构造独立，比如：
>
>    > 二维随机变量 $(X, Y) \sim N\left(\mathbf{0}, \mathbf{0}, 1, \frac{1}{4}, \frac{1}{3}\right)$, 设 $U=X-2 Y$ 和 $V=X+2 Y$
>    > $$
>    > \begin{array}{l}\operatorname{Cov}(U, V)=\operatorname{Cov}(\boldsymbol{X}-2 \boldsymbol{Y}, \boldsymbol{X}+2 \boldsymbol{Y})\\
>    > =\operatorname{Cov}(X, X)+2 \operatorname{Cov}(X, Y)-2 \operatorname{Cov}(X, Y)-4 \operatorname{Cov}(Y, Y) \\
>    > =\operatorname{Var}(X)-4 \operatorname{Var}(\boldsymbol{Y})=0
>    > \end{array}
>    > $$
>    > 所以 $U, V$ 独立
>
> 4. 卡方分布
>
>    若 $X_{i} \sim \chi^{2}\left(n_{i}\right), \quad i=1,2, \cdots, n$ ，且 $X_{i}$ 独立，则
>    $$
>    \sum_{i=1}^{n} \chi^{2}\left(n_{i}\right) \sim \chi^{2}\left(\sum_{i=1}^{n} n_{i}\right)
>    $$
> 	不可加：0–1 分布、几何分布、均匀分布、指数分布、t 分布

- P21，相互独立条件下，泊松分布可加。相互独立且 p 相同的条件下，二项分布可加
- P23，给定条件下，连续随机变量的条件分布函数与条件密度函数

$$
P(x|y)=\frac{P(x,y)}{P_Y(y)}
$$

- [重期望定理](https://zh.wikipedia.org/wiki/%E9%9B%99%E9%87%8D%E6%9C%9F%E6%9C%9B%E5%80%BC%E5%AE%9A%E7%90%86)

> $\mathrm{E}(X)=\mathrm{E}(\mathrm{E}(X \mid Y))$
> $$
> \begin{aligned}
> \mathrm{E}(\mathrm{E}(X \mid Y)) &=\sum_{y} \mathrm{E}(X \mid Y=y) \cdot \mathrm{P}(Y=y) \\
> &=\sum_{y}\left(\sum_{x} x \cdot \mathrm{P}(X=x \mid Y=y)\right) \cdot \mathrm{P}(Y=y) \\
> &=\sum_{y} \sum_{x} x \cdot \mathrm{P}(X=x \mid Y=y) \cdot \mathrm{P}(Y=y) \\
> &=\sum_{y} \sum_{x} x \cdot \mathrm{P}(Y=y \mid X=x) \cdot \mathrm{P}(X=x) \\
> &=\sum_{x} \sum_{y} x \cdot \mathrm{P}(Y=y \mid X=x) \cdot \mathrm{P}(X=x) \\
> &=\sum_{x} x \cdot \mathrm{P}(X=x) \cdot\left(\sum_{y} \mathrm{P}(Y=y \mid X=x)\right) \\
> &=\sum_{x} x \cdot \mathrm{P}(X=x) \\
> &=\mathrm{E}(X)
> \end{aligned}
> $$

